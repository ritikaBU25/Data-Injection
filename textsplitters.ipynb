{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16dda9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}, page_content='1) List relevant regulatory requirements and how they are addressed \\nOrion’s compliance baseline is organized around four core regulatory intent areas that \\ncommonly apply to agentic AI solutions: (a) personal data protection and privacy, (b) \\nhealth-related data protection (where applicable), (c) electronic records and signatures \\n/ auditability, and (d) AI governance and risk management. For each intent area Orion \\nimplements control families that satisfy the objectives of regulation and good-practice \\nguidance: policy & governance, technical controls, operational controls, and evidence \\n& reporting. \\n• Policy & Governance — Define ownership and responsibilities (Compliance Owner, \\nData Owner, System Owner), maintain a documented Solution Profile (single-source-of-\\ntruth for the system), and operate a formal risk register and change control process so \\nevery design change is risk-assessed and approved. \\n• Technical Controls — Enforce strong encryption at rest and in transit, role-based \\naccess control (least privilege), key management, pseudonymization or tokenization of \\nidentifiers, and data residency configuration to limit where data may be stored or \\nprocessed. \\n• Operational Controls — Implement human-in-the-loop review gates for sensitive \\noutputs, routine compliance training for staff, periodic control self-assessments, \\nscheduled penetration and security testing, and a documented incident response / \\nescalation process. \\n• Evidence & Reporting — Retain immutable audit logs, produce periodic compliance \\nreports, and maintain versioned artifacts (design docs, test reports, validation \\nevidence) to demonstrate adherence during internal or regulatory reviews. \\n(These control families map to legal/regulatory objectives such as privacy, security, \\nrecord integrity and AI risk management; see full regulation texts and guidance for exact \\nrequirements.) GDPR+2HHS.gov+2 \\n \\n2) Comprehensive Error Handling — design and operational requirements \\nRobust error handling is essential for safe, auditable operation of an agentic AI system. \\nOrion’s approach treats error handling as a first-class compliance control that supports \\navailability, traceability and safe failure. \\nDesign principles \\n• Fail-safe defaults: If a component fails or behavior is uncertain, the system \\nshould prefer safe, minimal actions (e.g., halt an automated JIRA commit and \\nsurface a human review item instead).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 1, 'page_label': '2'}, page_content='• Graceful degradation: Non-critical features degrade first; core safety and \\ncompliance features (sanitization, consent checks, audit logging) remain active \\neven under partial failure. \\n• Clear classification and routing: Errors are classified (transient network, rate-\\nlimited API, permanent configuration failure, data validation error) and routed to \\nappropriate handlers (automatic retry, queued reprocessing, human escalation). \\nImplementation controls \\n• Centralized error management service that normalizes error events from \\nagents, produces structured error records (error code, component, time, input \\ncontext, stack), and forwards them to the incident queue. \\n• Automated triage rules that map classes of errors to actions (retry, queue, \\nrollback, alert). Retries use backoff policies (see next section). Permanent \\nfailures produce structured remediation tasks (with owner and SLA). \\n• Observability & runbooks — every error type has an associated runbook (steps \\nto investigate, revert, restore, and report). Key metrics (error rate, time to \\nremediation, reprocessing success rate) are instrumented and monitored. \\n• Data protection on failure — when errors involve data (e.g., partial writes), \\nOrion applies transactional or compensating operations to avoid leaving PII/PHI \\nin an inconsistent or exposed state. \\nOperational controls \\n• Automated alerts for thresholds (error spikes, queue growth) routed to on-call \\nteams with escalation rules. \\n• Weekly error reviews to identify systemic issues and update runbooks. \\n• Preservation of input context (masked where necessary) in the error record so \\nteams can troubleshoot without exposing sensitive data. \\n \\n3) Retry Mechanisms — exponential backoff + jitter best practice and configuration \\nrecommendations \\nFor transient failures (temporary network blips, rate limit responses, brief downstream \\noutages) Orion uses exponential backoff with jitter to maximize reliability while \\nminimizing load amplification. \\nWhy exponential backoff + jitter \\n• Exponential backoff spaces retries so the system does not continuously hammer \\na recovering endpoint; jitter (randomized delay) prevents many clients from'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 2, 'page_label': '3'}, page_content='synchronizing retries and causing a “retry storm. ” This pattern is recommended \\nby major cloud providers and architecture guides. Amazon Web Services, Inc. \\nRecommended configuration pattern (example defaults) \\n• Max attempts: 5 (configurable per integration) \\n• Base delay: 200 ms \\n• Backoff factor: 2 (delay doubles each retry) \\n• Jitter: use full jitter or decorrelated jitter (i.e., randomize delay between 0 and \\ncurrent backoff interval) to avoid clumping \\n• Max backoff cap: 30 seconds (prevent indefinite waits) \\n• Retryable error classes: transient HTTP 408, 429, 5xx; network timeouts; \\nconnection reset; transient database or message broker errors. Do not retry on \\n4xx errors that indicate client fault (unless explicitly idempotent and safe). \\n• Idempotency & safe retries: for any retried operation, design APIs and \\noperations to be idempotent or employ a request-idempotency key to prevent \\nrepeated side effects (e.g., duplicate JIRA issues). \\nImplementation notes \\n• Use built-in client SDK retry functionality when available (they often implement \\nrecommended backoff/jitter) and instrument the retry events in metrics (retry \\ncount histogram, retry latency distribution). \\n• Log each retry attempt with correlation id and original input context (masked as \\nrequired) so retries are auditable and diagnosable. \\n• Provide circuit-breaker logic: if a downstream service fails repeatedly, trip the \\ncircuit (stop retries temporarily) and open an alert so operators can investigate. \\n \\n4) Audit Trail Logs — design for completeness, immutability, and forensic readiness \\nAuditability is a cornerstone of compliance. Orion designs its logging and audit trail \\nsystem so it is comprehensive, tamper-evident, and queryable for investigations and \\nregulatory review. \\nWhat to log (minimum set) \\n• Identity of actor (human user id or agent id), role and authentication context. \\n• Action performed (create/update/delete/approve/execute), including object \\nidentifiers (e.g., solution profile id, JIRA ticket id).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 3, 'page_label': '4'}, page_content='• Full event timestamp (ISO8601 with timezone) and source system/component. \\n• Pre- and post-state for critical changes (before/after snapshot or a secure diff). \\n• Correlation IDs to relate multi-step flows and upstream/downstream calls. \\n• Retention and disposition metadata (who archived the record, why, retention \\nexpiry). \\nImmutability & integrity \\n• Store audit logs in append-only, tamper-resistant storage (WORM / write-once \\nstorage, or digital signatures/hashes anchored to a secure ledger). Adopt \\nperiodic archival to immutable backups that are integrity-checked. NIST \\nguidance highlights write-once media and digital signatures as ways to prevent \\nlog tampering. NIST Publications \\nAccess & encryption \\n• Encrypt logs at rest and in transit. Restrict read access to authorized compliance \\nand audit roles; restrict write access to trusted system services only. Maintain \\nstrong logging-service authentication and rotate log-access credentials \\nfrequently. \\nMonitoring & alerting \\n• Deploy automated integrity checks (periodic hash comparisons, verified \\nbackups) and alerts for anomalous deletion attempts, sudden log volume \\nspikes, or gaps in expected event sequences. \\n• Provide an audit-query interface for authorized reviewers that supports \\nreconstructed timelines and exportable evidence packages (signed and time-\\nstamped). \\nRetention & legal hold \\n• Implement configurable retention policies per data classification. When an \\ninvestigation or legal preservation is required, add a legal hold to prevent \\ndeletion/archival of relevant logs. \\n \\n5) Quality Assurance — validation checkpoints throughout the workflow (practical \\npipeline) \\nQuality is enforced through a layered approach combining automated testing, \\nenvironment gating, human review and production monitoring. \\nPipeline & checkpoints'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 4, 'page_label': '5'}, page_content='1. Pre-commit checks: linters and static analysis detect code style and certain \\nclasses of security issues before code merges. \\n2. CI automated tests: every commit triggers unit tests and integration tests to \\nvalidate functional correctness and catch regressions. Include schema, \\ncontract, and input-sanitization tests for AI prompt processing and output \\nformatting. \\n3. Stage / pre-production: deploy release candidate to a staging environment that \\nmirrors production (data subset or synthetic data). Run end-to-end workflows, \\nperformance tests, and security scans here. Use synthetic or pseudonymized \\ndata to avoid exposing real PII/PHI. \\n4. Human acceptance / compliance review: for changes that affect compliance \\ncontrols (data handling, consent flows, AI sanitization, auditing), require sign-off \\nby compliance or quality owners before deployment. This human-in-the-loop \\nstep validates non-functional requirements (auditability, traceability, masking). \\n5. Canary / progressive rollout: release to a small segment of traffic and monitor \\nkey metrics (error rate, latency, data leak indicators, unusual content generation) \\nbefore full rollout. \\n6. Post-deployment verification: run smoke tests and automated consistency \\nchecks; confirm audit logs were generated for the run; verify that key control \\npoints (consent checks, sanitization) functioned as expected. \\n7. Production monitoring and continuous feedback: instrument telemetry \\n(SLOs/SLA metrics, error budgets, data quality, drift indicators) and feed back \\nresults into the development backlog and model/prompt governance process. \\nTest types and coverage \\n• Unit tests for deterministic logic and sanitization functions. \\n• Integration tests for agent orchestration flows (e.g., prompt → agent decisions → \\nJIRA API interactions). \\n• Contract tests for API compatibility with external services. \\n• Security tests including SAST, DAST and periodic penetration tests. \\n• Data quality tests to ensure data pipeline transformations do not leak identifiers \\nor corrupt content. \\nGovernance & evidence'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 5, 'page_label': '6'}, page_content='• Maintain a test evidence repository (test plans, results, sign-offs) linked to each \\nrelease and solution profile. This evidence is part of the compliance package for \\naudits. \\n• Enforce minimum test coverage thresholds and failure-blocking policies for \\nreleases that touch sensitive controls. \\n \\nPractical operational items to include in Orion’s SOPs / Runbooks \\n• Metric dashboards: Retry rates, error rates per component, mean time to \\nremediation, audit log integrity check results, percent of outputs flagged for \\nhuman review. \\n• Runbooks & playbooks: Clear step-by-step remediation instructions for \\ncommon failures, with assigned roles and escalation paths. \\n• Periodic reviews: Monthly error trend reviews, quarterly control self-\\nassessments, annual third-party audits. \\n• Data handling procedures: Masking/pseudonymization libraries, key \\nmanagement schedule, data residency enforcement checklist. \\n \\nKey sources (authoritative guidance) \\n• GDPR reference text (for data-protection objectives and rights). GDPR \\n• HIPAA/HHS guidance (technical safeguards overview and encryption \\nrecommendations). HHS.gov \\n• FDA guidance on electronic records and signatures (Part 11) for audit and record \\nintegrity expectations. U.S. Food and Drug Administration \\n• NIST guidance on log management and audit trail integrity (write-once, \\nsignatures). NIST Publications \\n• Exponential backoff + jitter best practices (AWS builders guidance). Amazon \\nWeb Services, Inc.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader('Compliance.pdf')\n",
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b603e1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}, page_content='1) List relevant regulatory requirements and how they are addressed \\nOrion’s compliance baseline is organized around four core regulatory intent areas that \\ncommonly apply to agentic AI solutions: (a) personal data protection and privacy, (b) \\nhealth-related data protection (where applicable), (c) electronic records and signatures \\n/ auditability, and (d) AI governance and risk management. For each intent area Orion'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}, page_content='implements control families that satisfy the objectives of regulation and good-practice \\nguidance: policy & governance, technical controls, operational controls, and evidence \\n& reporting. \\n• Policy & Governance — Define ownership and responsibilities (Compliance Owner, \\nData Owner, System Owner), maintain a documented Solution Profile (single-source-of-\\ntruth for the system), and operate a formal risk register and change control process so \\nevery design change is risk-assessed and approved.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}, page_content='• Technical Controls — Enforce strong encryption at rest and in transit, role-based \\naccess control (least privilege), key management, pseudonymization or tokenization of \\nidentifiers, and data residency configuration to limit where data may be stored or \\nprocessed. \\n• Operational Controls — Implement human-in-the-loop review gates for sensitive \\noutputs, routine compliance training for staff, periodic control self-assessments,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}, page_content='scheduled penetration and security testing, and a documented incident response / \\nescalation process. \\n• Evidence & Reporting — Retain immutable audit logs, produce periodic compliance \\nreports, and maintain versioned artifacts (design docs, test reports, validation \\nevidence) to demonstrate adherence during internal or regulatory reviews. \\n(These control families map to legal/regulatory objectives such as privacy, security,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}, page_content='record integrity and AI risk management; see full regulation texts and guidance for exact \\nrequirements.) GDPR+2HHS.gov+2 \\n \\n2) Comprehensive Error Handling — design and operational requirements \\nRobust error handling is essential for safe, auditable operation of an agentic AI system. \\nOrion’s approach treats error handling as a first-class compliance control that supports \\navailability, traceability and safe failure. \\nDesign principles'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}, page_content='Design principles \\n• Fail-safe defaults: If a component fails or behavior is uncertain, the system \\nshould prefer safe, minimal actions (e.g., halt an automated JIRA commit and \\nsurface a human review item instead).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 1, 'page_label': '2'}, page_content='• Graceful degradation: Non-critical features degrade first; core safety and \\ncompliance features (sanitization, consent checks, audit logging) remain active \\neven under partial failure. \\n• Clear classification and routing: Errors are classified (transient network, rate-\\nlimited API, permanent configuration failure, data validation error) and routed to \\nappropriate handlers (automatic retry, queued reprocessing, human escalation). \\nImplementation controls'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 1, 'page_label': '2'}, page_content='Implementation controls \\n• Centralized error management service that normalizes error events from \\nagents, produces structured error records (error code, component, time, input \\ncontext, stack), and forwards them to the incident queue. \\n• Automated triage rules that map classes of errors to actions (retry, queue, \\nrollback, alert). Retries use backoff policies (see next section). Permanent \\nfailures produce structured remediation tasks (with owner and SLA).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 1, 'page_label': '2'}, page_content='• Observability & runbooks — every error type has an associated runbook (steps \\nto investigate, revert, restore, and report). Key metrics (error rate, time to \\nremediation, reprocessing success rate) are instrumented and monitored. \\n• Data protection on failure — when errors involve data (e.g., partial writes), \\nOrion applies transactional or compensating operations to avoid leaving PII/PHI \\nin an inconsistent or exposed state. \\nOperational controls'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 1, 'page_label': '2'}, page_content='Operational controls \\n• Automated alerts for thresholds (error spikes, queue growth) routed to on-call \\nteams with escalation rules. \\n• Weekly error reviews to identify systemic issues and update runbooks. \\n• Preservation of input context (masked where necessary) in the error record so \\nteams can troubleshoot without exposing sensitive data. \\n \\n3) Retry Mechanisms — exponential backoff + jitter best practice and configuration \\nrecommendations'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 1, 'page_label': '2'}, page_content='recommendations \\nFor transient failures (temporary network blips, rate limit responses, brief downstream \\noutages) Orion uses exponential backoff with jitter to maximize reliability while \\nminimizing load amplification. \\nWhy exponential backoff + jitter \\n• Exponential backoff spaces retries so the system does not continuously hammer \\na recovering endpoint; jitter (randomized delay) prevents many clients from'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 2, 'page_label': '3'}, page_content='synchronizing retries and causing a “retry storm. ” This pattern is recommended \\nby major cloud providers and architecture guides. Amazon Web Services, Inc. \\nRecommended configuration pattern (example defaults) \\n• Max attempts: 5 (configurable per integration) \\n• Base delay: 200 ms \\n• Backoff factor: 2 (delay doubles each retry) \\n• Jitter: use full jitter or decorrelated jitter (i.e., randomize delay between 0 and \\ncurrent backoff interval) to avoid clumping'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 2, 'page_label': '3'}, page_content='current backoff interval) to avoid clumping \\n• Max backoff cap: 30 seconds (prevent indefinite waits) \\n• Retryable error classes: transient HTTP 408, 429, 5xx; network timeouts; \\nconnection reset; transient database or message broker errors. Do not retry on \\n4xx errors that indicate client fault (unless explicitly idempotent and safe). \\n• Idempotency & safe retries: for any retried operation, design APIs and \\noperations to be idempotent or employ a request-idempotency key to prevent'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 2, 'page_label': '3'}, page_content='repeated side effects (e.g., duplicate JIRA issues). \\nImplementation notes \\n• Use built-in client SDK retry functionality when available (they often implement \\nrecommended backoff/jitter) and instrument the retry events in metrics (retry \\ncount histogram, retry latency distribution). \\n• Log each retry attempt with correlation id and original input context (masked as \\nrequired) so retries are auditable and diagnosable.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 2, 'page_label': '3'}, page_content='• Provide circuit-breaker logic: if a downstream service fails repeatedly, trip the \\ncircuit (stop retries temporarily) and open an alert so operators can investigate. \\n \\n4) Audit Trail Logs — design for completeness, immutability, and forensic readiness \\nAuditability is a cornerstone of compliance. Orion designs its logging and audit trail \\nsystem so it is comprehensive, tamper-evident, and queryable for investigations and \\nregulatory review. \\nWhat to log (minimum set)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 2, 'page_label': '3'}, page_content='regulatory review. \\nWhat to log (minimum set) \\n• Identity of actor (human user id or agent id), role and authentication context. \\n• Action performed (create/update/delete/approve/execute), including object \\nidentifiers (e.g., solution profile id, JIRA ticket id).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 3, 'page_label': '4'}, page_content='• Full event timestamp (ISO8601 with timezone) and source system/component. \\n• Pre- and post-state for critical changes (before/after snapshot or a secure diff). \\n• Correlation IDs to relate multi-step flows and upstream/downstream calls. \\n• Retention and disposition metadata (who archived the record, why, retention \\nexpiry). \\nImmutability & integrity \\n• Store audit logs in append-only, tamper-resistant storage (WORM / write-once'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 3, 'page_label': '4'}, page_content='storage, or digital signatures/hashes anchored to a secure ledger). Adopt \\nperiodic archival to immutable backups that are integrity-checked. NIST \\nguidance highlights write-once media and digital signatures as ways to prevent \\nlog tampering. NIST Publications \\nAccess & encryption \\n• Encrypt logs at rest and in transit. Restrict read access to authorized compliance \\nand audit roles; restrict write access to trusted system services only. Maintain'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 3, 'page_label': '4'}, page_content='strong logging-service authentication and rotate log-access credentials \\nfrequently. \\nMonitoring & alerting \\n• Deploy automated integrity checks (periodic hash comparisons, verified \\nbackups) and alerts for anomalous deletion attempts, sudden log volume \\nspikes, or gaps in expected event sequences. \\n• Provide an audit-query interface for authorized reviewers that supports \\nreconstructed timelines and exportable evidence packages (signed and time-\\nstamped). \\nRetention & legal hold'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 3, 'page_label': '4'}, page_content='stamped). \\nRetention & legal hold \\n• Implement configurable retention policies per data classification. When an \\ninvestigation or legal preservation is required, add a legal hold to prevent \\ndeletion/archival of relevant logs. \\n \\n5) Quality Assurance — validation checkpoints throughout the workflow (practical \\npipeline) \\nQuality is enforced through a layered approach combining automated testing, \\nenvironment gating, human review and production monitoring. \\nPipeline & checkpoints'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 4, 'page_label': '5'}, page_content='1. Pre-commit checks: linters and static analysis detect code style and certain \\nclasses of security issues before code merges. \\n2. CI automated tests: every commit triggers unit tests and integration tests to \\nvalidate functional correctness and catch regressions. Include schema, \\ncontract, and input-sanitization tests for AI prompt processing and output \\nformatting. \\n3. Stage / pre-production: deploy release candidate to a staging environment that'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 4, 'page_label': '5'}, page_content='mirrors production (data subset or synthetic data). Run end-to-end workflows, \\nperformance tests, and security scans here. Use synthetic or pseudonymized \\ndata to avoid exposing real PII/PHI. \\n4. Human acceptance / compliance review: for changes that affect compliance \\ncontrols (data handling, consent flows, AI sanitization, auditing), require sign-off \\nby compliance or quality owners before deployment. This human-in-the-loop'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 4, 'page_label': '5'}, page_content='step validates non-functional requirements (auditability, traceability, masking). \\n5. Canary / progressive rollout: release to a small segment of traffic and monitor \\nkey metrics (error rate, latency, data leak indicators, unusual content generation) \\nbefore full rollout. \\n6. Post-deployment verification: run smoke tests and automated consistency \\nchecks; confirm audit logs were generated for the run; verify that key control \\npoints (consent checks, sanitization) functioned as expected.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 4, 'page_label': '5'}, page_content='7. Production monitoring and continuous feedback: instrument telemetry \\n(SLOs/SLA metrics, error budgets, data quality, drift indicators) and feed back \\nresults into the development backlog and model/prompt governance process. \\nTest types and coverage \\n• Unit tests for deterministic logic and sanitization functions. \\n• Integration tests for agent orchestration flows (e.g., prompt → agent decisions → \\nJIRA API interactions). \\n• Contract tests for API compatibility with external services.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 4, 'page_label': '5'}, page_content='• Security tests including SAST, DAST and periodic penetration tests. \\n• Data quality tests to ensure data pipeline transformations do not leak identifiers \\nor corrupt content. \\nGovernance & evidence'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 5, 'page_label': '6'}, page_content='• Maintain a test evidence repository (test plans, results, sign-offs) linked to each \\nrelease and solution profile. This evidence is part of the compliance package for \\naudits. \\n• Enforce minimum test coverage thresholds and failure-blocking policies for \\nreleases that touch sensitive controls. \\n \\nPractical operational items to include in Orion’s SOPs / Runbooks \\n• Metric dashboards: Retry rates, error rates per component, mean time to'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 5, 'page_label': '6'}, page_content='remediation, audit log integrity check results, percent of outputs flagged for \\nhuman review. \\n• Runbooks & playbooks: Clear step-by-step remediation instructions for \\ncommon failures, with assigned roles and escalation paths. \\n• Periodic reviews: Monthly error trend reviews, quarterly control self-\\nassessments, annual third-party audits. \\n• Data handling procedures: Masking/pseudonymization libraries, key \\nmanagement schedule, data residency enforcement checklist.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 5, 'page_label': '6'}, page_content='Key sources (authoritative guidance) \\n• GDPR reference text (for data-protection objectives and rights). GDPR \\n• HIPAA/HHS guidance (technical safeguards overview and encryption \\nrecommendations). HHS.gov \\n• FDA guidance on electronic records and signatures (Part 11) for audit and record \\nintegrity expectations. U.S. Food and Drug Administration \\n• NIST guidance on log management and audit trail integrity (write-once, \\nsignatures). NIST Publications'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 5, 'page_label': '6'}, page_content='signatures). NIST Publications \\n• Exponential backoff + jitter best practices (AWS builders guidance). Amazon \\nWeb Services, Inc.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "final_doc=text_splitter.split_documents(docs)\n",
    "final_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "857e76c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='1) List relevant regulatory requirements and how they are addressed \n",
      "Orion’s compliance baseline is organized around four core regulatory intent areas that \n",
      "commonly apply to agentic AI solutions: (a) personal data protection and privacy, (b) \n",
      "health-related data protection (where applicable), (c) electronic records and signatures \n",
      "/ auditability, and (d) AI governance and risk management. For each intent area Orion' metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}\n",
      "page_content='implements control families that satisfy the objectives of regulation and good-practice \n",
      "guidance: policy & governance, technical controls, operational controls, and evidence \n",
      "& reporting. \n",
      "• Policy & Governance — Define ownership and responsibilities (Compliance Owner, \n",
      "Data Owner, System Owner), maintain a documented Solution Profile (single-source-of-\n",
      "truth for the system), and operate a formal risk register and change control process so \n",
      "every design change is risk-assessed and approved.' metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(final_doc[0])\n",
    "print(final_doc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac48bec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}, page_content='1) List relevant regulatory requirements and how they are addressed \\nOrion’s compliance baseline is organized around four core regulatory intent areas that \\ncommonly apply to agentic AI solutions: (a) personal data protection and privacy, (b) \\nhealth-related data protection (where applicable), (c) electronic records and signatures \\n/ auditability, and (d) AI governance and risk management. For each intent area Orion \\nimplements control families that satisfy the objectives of regulation and good-practice \\nguidance: policy & governance, technical controls, operational controls, and evidence \\n& reporting. \\n• Policy & Governance — Define ownership and responsibilities (Compliance Owner, \\nData Owner, System Owner), maintain a documented Solution Profile (single-source-of-\\ntruth for the system), and operate a formal risk register and change control process so \\nevery design change is risk-assessed and approved. \\n• Technical Controls — Enforce strong encryption at rest and in transit, role-based \\naccess control (least privilege), key management, pseudonymization or tokenization of \\nidentifiers, and data residency configuration to limit where data may be stored or \\nprocessed. \\n• Operational Controls — Implement human-in-the-loop review gates for sensitive \\noutputs, routine compliance training for staff, periodic control self-assessments, \\nscheduled penetration and security testing, and a documented incident response / \\nescalation process. \\n• Evidence & Reporting — Retain immutable audit logs, produce periodic compliance \\nreports, and maintain versioned artifacts (design docs, test reports, validation \\nevidence) to demonstrate adherence during internal or regulatory reviews. \\n(These control families map to legal/regulatory objectives such as privacy, security, \\nrecord integrity and AI risk management; see full regulation texts and guidance for exact \\nrequirements.) GDPR+2HHS.gov+2 \\n \\n2) Comprehensive Error Handling — design and operational requirements \\nRobust error handling is essential for safe, auditable operation of an agentic AI system. \\nOrion’s approach treats error handling as a first-class compliance control that supports \\navailability, traceability and safe failure. \\nDesign principles \\n• Fail-safe defaults: If a component fails or behavior is uncertain, the system \\nshould prefer safe, minimal actions (e.g., halt an automated JIRA commit and \\nsurface a human review item instead).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 1, 'page_label': '2'}, page_content='• Graceful degradation: Non-critical features degrade first; core safety and \\ncompliance features (sanitization, consent checks, audit logging) remain active \\neven under partial failure. \\n• Clear classification and routing: Errors are classified (transient network, rate-\\nlimited API, permanent configuration failure, data validation error) and routed to \\nappropriate handlers (automatic retry, queued reprocessing, human escalation). \\nImplementation controls \\n• Centralized error management service that normalizes error events from \\nagents, produces structured error records (error code, component, time, input \\ncontext, stack), and forwards them to the incident queue. \\n• Automated triage rules that map classes of errors to actions (retry, queue, \\nrollback, alert). Retries use backoff policies (see next section). Permanent \\nfailures produce structured remediation tasks (with owner and SLA). \\n• Observability & runbooks — every error type has an associated runbook (steps \\nto investigate, revert, restore, and report). Key metrics (error rate, time to \\nremediation, reprocessing success rate) are instrumented and monitored. \\n• Data protection on failure — when errors involve data (e.g., partial writes), \\nOrion applies transactional or compensating operations to avoid leaving PII/PHI \\nin an inconsistent or exposed state. \\nOperational controls \\n• Automated alerts for thresholds (error spikes, queue growth) routed to on-call \\nteams with escalation rules. \\n• Weekly error reviews to identify systemic issues and update runbooks. \\n• Preservation of input context (masked where necessary) in the error record so \\nteams can troubleshoot without exposing sensitive data. \\n \\n3) Retry Mechanisms — exponential backoff + jitter best practice and configuration \\nrecommendations \\nFor transient failures (temporary network blips, rate limit responses, brief downstream \\noutages) Orion uses exponential backoff with jitter to maximize reliability while \\nminimizing load amplification. \\nWhy exponential backoff + jitter \\n• Exponential backoff spaces retries so the system does not continuously hammer \\na recovering endpoint; jitter (randomized delay) prevents many clients from'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 2, 'page_label': '3'}, page_content='synchronizing retries and causing a “retry storm. ” This pattern is recommended \\nby major cloud providers and architecture guides. Amazon Web Services, Inc. \\nRecommended configuration pattern (example defaults) \\n• Max attempts: 5 (configurable per integration) \\n• Base delay: 200 ms \\n• Backoff factor: 2 (delay doubles each retry) \\n• Jitter: use full jitter or decorrelated jitter (i.e., randomize delay between 0 and \\ncurrent backoff interval) to avoid clumping \\n• Max backoff cap: 30 seconds (prevent indefinite waits) \\n• Retryable error classes: transient HTTP 408, 429, 5xx; network timeouts; \\nconnection reset; transient database or message broker errors. Do not retry on \\n4xx errors that indicate client fault (unless explicitly idempotent and safe). \\n• Idempotency & safe retries: for any retried operation, design APIs and \\noperations to be idempotent or employ a request-idempotency key to prevent \\nrepeated side effects (e.g., duplicate JIRA issues). \\nImplementation notes \\n• Use built-in client SDK retry functionality when available (they often implement \\nrecommended backoff/jitter) and instrument the retry events in metrics (retry \\ncount histogram, retry latency distribution). \\n• Log each retry attempt with correlation id and original input context (masked as \\nrequired) so retries are auditable and diagnosable. \\n• Provide circuit-breaker logic: if a downstream service fails repeatedly, trip the \\ncircuit (stop retries temporarily) and open an alert so operators can investigate. \\n \\n4) Audit Trail Logs — design for completeness, immutability, and forensic readiness \\nAuditability is a cornerstone of compliance. Orion designs its logging and audit trail \\nsystem so it is comprehensive, tamper-evident, and queryable for investigations and \\nregulatory review. \\nWhat to log (minimum set) \\n• Identity of actor (human user id or agent id), role and authentication context. \\n• Action performed (create/update/delete/approve/execute), including object \\nidentifiers (e.g., solution profile id, JIRA ticket id).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 3, 'page_label': '4'}, page_content='• Full event timestamp (ISO8601 with timezone) and source system/component. \\n• Pre- and post-state for critical changes (before/after snapshot or a secure diff). \\n• Correlation IDs to relate multi-step flows and upstream/downstream calls. \\n• Retention and disposition metadata (who archived the record, why, retention \\nexpiry). \\nImmutability & integrity \\n• Store audit logs in append-only, tamper-resistant storage (WORM / write-once \\nstorage, or digital signatures/hashes anchored to a secure ledger). Adopt \\nperiodic archival to immutable backups that are integrity-checked. NIST \\nguidance highlights write-once media and digital signatures as ways to prevent \\nlog tampering. NIST Publications \\nAccess & encryption \\n• Encrypt logs at rest and in transit. Restrict read access to authorized compliance \\nand audit roles; restrict write access to trusted system services only. Maintain \\nstrong logging-service authentication and rotate log-access credentials \\nfrequently. \\nMonitoring & alerting \\n• Deploy automated integrity checks (periodic hash comparisons, verified \\nbackups) and alerts for anomalous deletion attempts, sudden log volume \\nspikes, or gaps in expected event sequences. \\n• Provide an audit-query interface for authorized reviewers that supports \\nreconstructed timelines and exportable evidence packages (signed and time-\\nstamped). \\nRetention & legal hold \\n• Implement configurable retention policies per data classification. When an \\ninvestigation or legal preservation is required, add a legal hold to prevent \\ndeletion/archival of relevant logs. \\n \\n5) Quality Assurance — validation checkpoints throughout the workflow (practical \\npipeline) \\nQuality is enforced through a layered approach combining automated testing, \\nenvironment gating, human review and production monitoring. \\nPipeline & checkpoints'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 4, 'page_label': '5'}, page_content='1. Pre-commit checks: linters and static analysis detect code style and certain \\nclasses of security issues before code merges. \\n2. CI automated tests: every commit triggers unit tests and integration tests to \\nvalidate functional correctness and catch regressions. Include schema, \\ncontract, and input-sanitization tests for AI prompt processing and output \\nformatting. \\n3. Stage / pre-production: deploy release candidate to a staging environment that \\nmirrors production (data subset or synthetic data). Run end-to-end workflows, \\nperformance tests, and security scans here. Use synthetic or pseudonymized \\ndata to avoid exposing real PII/PHI. \\n4. Human acceptance / compliance review: for changes that affect compliance \\ncontrols (data handling, consent flows, AI sanitization, auditing), require sign-off \\nby compliance or quality owners before deployment. This human-in-the-loop \\nstep validates non-functional requirements (auditability, traceability, masking). \\n5. Canary / progressive rollout: release to a small segment of traffic and monitor \\nkey metrics (error rate, latency, data leak indicators, unusual content generation) \\nbefore full rollout. \\n6. Post-deployment verification: run smoke tests and automated consistency \\nchecks; confirm audit logs were generated for the run; verify that key control \\npoints (consent checks, sanitization) functioned as expected. \\n7. Production monitoring and continuous feedback: instrument telemetry \\n(SLOs/SLA metrics, error budgets, data quality, drift indicators) and feed back \\nresults into the development backlog and model/prompt governance process. \\nTest types and coverage \\n• Unit tests for deterministic logic and sanitization functions. \\n• Integration tests for agent orchestration flows (e.g., prompt → agent decisions → \\nJIRA API interactions). \\n• Contract tests for API compatibility with external services. \\n• Security tests including SAST, DAST and periodic penetration tests. \\n• Data quality tests to ensure data pipeline transformations do not leak identifiers \\nor corrupt content. \\nGovernance & evidence'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 5, 'page_label': '6'}, page_content='• Maintain a test evidence repository (test plans, results, sign-offs) linked to each \\nrelease and solution profile. This evidence is part of the compliance package for \\naudits. \\n• Enforce minimum test coverage thresholds and failure-blocking policies for \\nreleases that touch sensitive controls. \\n \\nPractical operational items to include in Orion’s SOPs / Runbooks \\n• Metric dashboards: Retry rates, error rates per component, mean time to \\nremediation, audit log integrity check results, percent of outputs flagged for \\nhuman review. \\n• Runbooks & playbooks: Clear step-by-step remediation instructions for \\ncommon failures, with assigned roles and escalation paths. \\n• Periodic reviews: Monthly error trend reviews, quarterly control self-\\nassessments, annual third-party audits. \\n• Data handling procedures: Masking/pseudonymization libraries, key \\nmanagement schedule, data residency enforcement checklist. \\n \\nKey sources (authoritative guidance) \\n• GDPR reference text (for data-protection objectives and rights). GDPR \\n• HIPAA/HHS guidance (technical safeguards overview and encryption \\nrecommendations). HHS.gov \\n• FDA guidance on electronic records and signatures (Part 11) for audit and record \\nintegrity expectations. U.S. Food and Drug Administration \\n• NIST guidance on log management and audit trail integrity (write-once, \\nsignatures). NIST Publications \\n• Exponential backoff + jitter best practices (AWS builders guidance). Amazon \\nWeb Services, Inc.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader('Compliance.pdf')\n",
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2277d4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Attended Agentic AI Session by Himanshu\n",
      "Prepared Orion use case ppt'\n"
     ]
    }
   ],
   "source": [
    "speech=\"\"\n",
    "with open('Demo.txt') as f:\n",
    "    speech=f.read()\n",
    "speech\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=5)\n",
    "text=text_splitter.create_documents([speech])\n",
    "print(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7acf86bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}, page_content='1) List relevant regulatory requirements and how they are addressed \\nOrion’s compliance baseline is organized around four core regulatory intent areas that \\ncommonly apply to agentic AI solutions: (a) personal data protection and privacy, (b) \\nhealth-related data protection (where applicable), (c) electronic records and signatures \\n/ auditability, and (d) AI governance and risk management. For each intent area Orion \\nimplements control families that satisfy the objectives of regulation and good-practice \\nguidance: policy & governance, technical controls, operational controls, and evidence \\n& reporting. \\n• Policy & Governance — Define ownership and responsibilities (Compliance Owner, \\nData Owner, System Owner), maintain a documented Solution Profile (single-source-of-\\ntruth for the system), and operate a formal risk register and change control process so \\nevery design change is risk-assessed and approved. \\n• Technical Controls — Enforce strong encryption at rest and in transit, role-based \\naccess control (least privilege), key management, pseudonymization or tokenization of \\nidentifiers, and data residency configuration to limit where data may be stored or \\nprocessed. \\n• Operational Controls — Implement human-in-the-loop review gates for sensitive \\noutputs, routine compliance training for staff, periodic control self-assessments, \\nscheduled penetration and security testing, and a documented incident response / \\nescalation process. \\n• Evidence & Reporting — Retain immutable audit logs, produce periodic compliance \\nreports, and maintain versioned artifacts (design docs, test reports, validation \\nevidence) to demonstrate adherence during internal or regulatory reviews. \\n(These control families map to legal/regulatory objectives such as privacy, security, \\nrecord integrity and AI risk management; see full regulation texts and guidance for exact \\nrequirements.) GDPR+2HHS.gov+2 \\n \\n2) Comprehensive Error Handling — design and operational requirements \\nRobust error handling is essential for safe, auditable operation of an agentic AI system. \\nOrion’s approach treats error handling as a first-class compliance control that supports \\navailability, traceability and safe failure. \\nDesign principles \\n• Fail-safe defaults: If a component fails or behavior is uncertain, the system \\nshould prefer safe, minimal actions (e.g., halt an automated JIRA commit and \\nsurface a human review item instead).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 1, 'page_label': '2'}, page_content='• Graceful degradation: Non-critical features degrade first; core safety and \\ncompliance features (sanitization, consent checks, audit logging) remain active \\neven under partial failure. \\n• Clear classification and routing: Errors are classified (transient network, rate-\\nlimited API, permanent configuration failure, data validation error) and routed to \\nappropriate handlers (automatic retry, queued reprocessing, human escalation). \\nImplementation controls \\n• Centralized error management service that normalizes error events from \\nagents, produces structured error records (error code, component, time, input \\ncontext, stack), and forwards them to the incident queue. \\n• Automated triage rules that map classes of errors to actions (retry, queue, \\nrollback, alert). Retries use backoff policies (see next section). Permanent \\nfailures produce structured remediation tasks (with owner and SLA). \\n• Observability & runbooks — every error type has an associated runbook (steps \\nto investigate, revert, restore, and report). Key metrics (error rate, time to \\nremediation, reprocessing success rate) are instrumented and monitored. \\n• Data protection on failure — when errors involve data (e.g., partial writes), \\nOrion applies transactional or compensating operations to avoid leaving PII/PHI \\nin an inconsistent or exposed state. \\nOperational controls \\n• Automated alerts for thresholds (error spikes, queue growth) routed to on-call \\nteams with escalation rules. \\n• Weekly error reviews to identify systemic issues and update runbooks. \\n• Preservation of input context (masked where necessary) in the error record so \\nteams can troubleshoot without exposing sensitive data. \\n \\n3) Retry Mechanisms — exponential backoff + jitter best practice and configuration \\nrecommendations \\nFor transient failures (temporary network blips, rate limit responses, brief downstream \\noutages) Orion uses exponential backoff with jitter to maximize reliability while \\nminimizing load amplification. \\nWhy exponential backoff + jitter \\n• Exponential backoff spaces retries so the system does not continuously hammer \\na recovering endpoint; jitter (randomized delay) prevents many clients from'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 2, 'page_label': '3'}, page_content='synchronizing retries and causing a “retry storm. ” This pattern is recommended \\nby major cloud providers and architecture guides. Amazon Web Services, Inc. \\nRecommended configuration pattern (example defaults) \\n• Max attempts: 5 (configurable per integration) \\n• Base delay: 200 ms \\n• Backoff factor: 2 (delay doubles each retry) \\n• Jitter: use full jitter or decorrelated jitter (i.e., randomize delay between 0 and \\ncurrent backoff interval) to avoid clumping \\n• Max backoff cap: 30 seconds (prevent indefinite waits) \\n• Retryable error classes: transient HTTP 408, 429, 5xx; network timeouts; \\nconnection reset; transient database or message broker errors. Do not retry on \\n4xx errors that indicate client fault (unless explicitly idempotent and safe). \\n• Idempotency & safe retries: for any retried operation, design APIs and \\noperations to be idempotent or employ a request-idempotency key to prevent \\nrepeated side effects (e.g., duplicate JIRA issues). \\nImplementation notes \\n• Use built-in client SDK retry functionality when available (they often implement \\nrecommended backoff/jitter) and instrument the retry events in metrics (retry \\ncount histogram, retry latency distribution). \\n• Log each retry attempt with correlation id and original input context (masked as \\nrequired) so retries are auditable and diagnosable. \\n• Provide circuit-breaker logic: if a downstream service fails repeatedly, trip the \\ncircuit (stop retries temporarily) and open an alert so operators can investigate. \\n \\n4) Audit Trail Logs — design for completeness, immutability, and forensic readiness \\nAuditability is a cornerstone of compliance. Orion designs its logging and audit trail \\nsystem so it is comprehensive, tamper-evident, and queryable for investigations and \\nregulatory review. \\nWhat to log (minimum set) \\n• Identity of actor (human user id or agent id), role and authentication context. \\n• Action performed (create/update/delete/approve/execute), including object \\nidentifiers (e.g., solution profile id, JIRA ticket id).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 3, 'page_label': '4'}, page_content='• Full event timestamp (ISO8601 with timezone) and source system/component. \\n• Pre- and post-state for critical changes (before/after snapshot or a secure diff). \\n• Correlation IDs to relate multi-step flows and upstream/downstream calls. \\n• Retention and disposition metadata (who archived the record, why, retention \\nexpiry). \\nImmutability & integrity \\n• Store audit logs in append-only, tamper-resistant storage (WORM / write-once \\nstorage, or digital signatures/hashes anchored to a secure ledger). Adopt \\nperiodic archival to immutable backups that are integrity-checked. NIST \\nguidance highlights write-once media and digital signatures as ways to prevent \\nlog tampering. NIST Publications \\nAccess & encryption \\n• Encrypt logs at rest and in transit. Restrict read access to authorized compliance \\nand audit roles; restrict write access to trusted system services only. Maintain \\nstrong logging-service authentication and rotate log-access credentials \\nfrequently. \\nMonitoring & alerting \\n• Deploy automated integrity checks (periodic hash comparisons, verified \\nbackups) and alerts for anomalous deletion attempts, sudden log volume \\nspikes, or gaps in expected event sequences. \\n• Provide an audit-query interface for authorized reviewers that supports \\nreconstructed timelines and exportable evidence packages (signed and time-\\nstamped). \\nRetention & legal hold \\n• Implement configurable retention policies per data classification. When an \\ninvestigation or legal preservation is required, add a legal hold to prevent \\ndeletion/archival of relevant logs. \\n \\n5) Quality Assurance — validation checkpoints throughout the workflow (practical \\npipeline) \\nQuality is enforced through a layered approach combining automated testing, \\nenvironment gating, human review and production monitoring. \\nPipeline & checkpoints'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 4, 'page_label': '5'}, page_content='1. Pre-commit checks: linters and static analysis detect code style and certain \\nclasses of security issues before code merges. \\n2. CI automated tests: every commit triggers unit tests and integration tests to \\nvalidate functional correctness and catch regressions. Include schema, \\ncontract, and input-sanitization tests for AI prompt processing and output \\nformatting. \\n3. Stage / pre-production: deploy release candidate to a staging environment that \\nmirrors production (data subset or synthetic data). Run end-to-end workflows, \\nperformance tests, and security scans here. Use synthetic or pseudonymized \\ndata to avoid exposing real PII/PHI. \\n4. Human acceptance / compliance review: for changes that affect compliance \\ncontrols (data handling, consent flows, AI sanitization, auditing), require sign-off \\nby compliance or quality owners before deployment. This human-in-the-loop \\nstep validates non-functional requirements (auditability, traceability, masking). \\n5. Canary / progressive rollout: release to a small segment of traffic and monitor \\nkey metrics (error rate, latency, data leak indicators, unusual content generation) \\nbefore full rollout. \\n6. Post-deployment verification: run smoke tests and automated consistency \\nchecks; confirm audit logs were generated for the run; verify that key control \\npoints (consent checks, sanitization) functioned as expected. \\n7. Production monitoring and continuous feedback: instrument telemetry \\n(SLOs/SLA metrics, error budgets, data quality, drift indicators) and feed back \\nresults into the development backlog and model/prompt governance process. \\nTest types and coverage \\n• Unit tests for deterministic logic and sanitization functions. \\n• Integration tests for agent orchestration flows (e.g., prompt → agent decisions → \\nJIRA API interactions). \\n• Contract tests for API compatibility with external services. \\n• Security tests including SAST, DAST and periodic penetration tests. \\n• Data quality tests to ensure data pipeline transformations do not leak identifiers \\nor corrupt content. \\nGovernance & evidence'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-14T15:49:07+05:30', 'author': 'Ritika Kulkarni', 'moddate': '2025-10-14T15:49:07+05:30', 'source': 'Compliance.pdf', 'total_pages': 6, 'page': 5, 'page_label': '6'}, page_content='• Maintain a test evidence repository (test plans, results, sign-offs) linked to each \\nrelease and solution profile. This evidence is part of the compliance package for \\naudits. \\n• Enforce minimum test coverage thresholds and failure-blocking policies for \\nreleases that touch sensitive controls. \\n \\nPractical operational items to include in Orion’s SOPs / Runbooks \\n• Metric dashboards: Retry rates, error rates per component, mean time to \\nremediation, audit log integrity check results, percent of outputs flagged for \\nhuman review. \\n• Runbooks & playbooks: Clear step-by-step remediation instructions for \\ncommon failures, with assigned roles and escalation paths. \\n• Periodic reviews: Monthly error trend reviews, quarterly control self-\\nassessments, annual third-party audits. \\n• Data handling procedures: Masking/pseudonymization libraries, key \\nmanagement schedule, data residency enforcement checklist. \\n \\nKey sources (authoritative guidance) \\n• GDPR reference text (for data-protection objectives and rights). GDPR \\n• HIPAA/HHS guidance (technical safeguards overview and encryption \\nrecommendations). HHS.gov \\n• FDA guidance on electronic records and signatures (Part 11) for audit and record \\nintegrity expectations. U.S. Food and Drug Administration \\n• NIST guidance on log management and audit trail integrity (write-once, \\nsignatures). NIST Publications \\n• Exponential backoff + jitter best practices (AWS builders guidance). Amazon \\nWeb Services, Inc.')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter=CharacterTextSplitter(separator=\"\\n\\n\", chunk_size=100, chunk_overlap=5)\n",
    "text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f6d88ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Attended Agentic AI Session by Himanshu\n",
      "Prepared Orion use case ppt\n",
      "Presented Orion use cases using PPT\n",
      "Revised logging module and log levels\n",
      "Revised Pydantic BaseModel and field validation\n",
      "Solved Leetcode'\n"
     ]
    }
   ],
   "source": [
    "speech=\"\"\n",
    "with open('Demo.txt') as f:\n",
    "    speech=f.read()\n",
    "text_splitter=CharacterTextSplitter(separator=\"\\n\\n\", chunk_size=100, chunk_overlap=5)\n",
    "text=text_splitter.create_documents([speech])\n",
    "print(text[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
